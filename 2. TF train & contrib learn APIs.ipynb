{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TF Train API***\n",
    "\n",
    "https://www.tensorflow.org/get_started/get_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ***optimizer*** changes tf variables to minimize a loss function. The simplest is ***gradient descent***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0:\t[array([-0.21999997], dtype=float32), array([-0.456], dtype=float32), 4.0181446]\n",
      "Iteration 333:\t[array([-0.99050313], dtype=float32), array([ 0.97207808], dtype=float32), 0.00052083354]\n",
      "Iteration 666:\t[array([-0.9998281], dtype=float32), array([ 0.99949461], dtype=float32), 1.7062862e-07]\n",
      "Iteration 999:\t[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32), 5.6999738e-11]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Linear model:\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "linear_model = W * x + b\n",
    "\n",
    "# Loss function:\n",
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "\n",
    "# Gradient descent optimizer:\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# Get a TF session and initialize the variables:\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "# Run the graph:\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x: x_train, y: y_train})\n",
    "    if i % 333 == 0:\n",
    "        print(\"Iteration \" + str(i) + \":\" + \"\\t\" + str(sess.run([W, b, loss], {x: x_train, y: y_train})))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TF Contrib Learn API***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same linear regression problem with tf.contrib.learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# tf.contrib abstraction for features (placeholders) and estimator:\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\n",
    "\n",
    "# Train and test data:\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "# Functions to pass data into estimator:\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, batch_size=4, num_epochs=1000)\n",
    "eval_input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000)\n",
    "\n",
    "# Update the model (estimator) with the training data:\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Evaluate the model:\n",
    "train_loss = estimator.evaluate(input_fn=input_fn)\n",
    "eval_loss = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"Train loss: %r\" % train_loss)\n",
    "print(\"Eval loss: %r\" % eval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above uses a predefined Linear Regression model. You can also make a custom model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Isaac\\AppData\\Local\\Temp\\tmpmx6aij98\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_is_chief': True, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002768FD50518>, '_task_type': None, '_num_worker_replicas': 0, '_evaluation_master': '', '_environment': 'local', '_tf_random_seed': None, '_master': '', '_keep_checkpoint_max': 5, '_session_config': None, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\Isaac\\\\AppData\\\\Local\\\\Temp\\\\tmpmx6aij98', '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Isaac\\AppData\\Local\\Temp\\tmpmx6aij98\\model.ckpt.\n",
      "INFO:tensorflow:loss = 159.417773707, step = 1\n",
      "INFO:tensorflow:global_step/sec: 621.38\n",
      "INFO:tensorflow:loss = 0.056955600223, step = 101 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 749.698\n",
      "INFO:tensorflow:loss = 0.00717295500921, step = 201 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 797.099\n",
      "INFO:tensorflow:loss = 0.00053820885789, step = 301 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 749.847\n",
      "INFO:tensorflow:loss = 7.32073990388e-05, step = 401 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.669\n",
      "INFO:tensorflow:loss = 4.00327585636e-06, step = 501 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.698\n",
      "INFO:tensorflow:loss = 4.51347125038e-07, step = 601 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.4\n",
      "INFO:tensorflow:loss = 3.32345742941e-08, step = 701 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 852.4\n",
      "INFO:tensorflow:loss = 2.05186087566e-09, step = 801 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 734.917\n",
      "INFO:tensorflow:loss = 1.66789389989e-10, step = 901 (0.137 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Isaac\\AppData\\Local\\Temp\\tmpmx6aij98\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.04084382514e-11.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-24-21:00:18\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Isaac\\AppData\\Local\\Temp\\tmpmx6aij98\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-24-21:00:19\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.72819e-11\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-24-21:00:19\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Isaac\\AppData\\Local\\Temp\\tmpmx6aij98\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-24-21:00:20\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101007\n",
      "Train loss: {'loss': 1.7281889e-11, 'global_step': 1000}\n",
      "Eval loss: {'loss': 0.010100735, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# Define model that takes features, labels, and mode: #\n",
    "#######################################################\n",
    "def model(features, labels, mode):\n",
    "    \n",
    "    # Linear model and loss:\n",
    "    W = tf.get_variable(\"W\", shape=[1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", shape=[1], dtype=tf.float64)\n",
    "    y = W * features[\"x\"] + b\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    \n",
    "    # Training subgraph:\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = tf.group(optimizer.minimize(loss), tf.assign_add(global_step, 1))\n",
    "    \n",
    "    # Return a \"ModelFnOps\" instance:\n",
    "    return tf.contrib.learn.ModelFnOps(mode=mode, predictions=y, loss=loss, train_op=train)\n",
    "\n",
    "###########################################\n",
    "# As before, but using this custom model: #\n",
    "###########################################\n",
    "\n",
    "# tf.contrib abstraction for features (placeholders) and estimator:\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model)\n",
    "\n",
    "# Train and test data:\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "# Functions to pass data into estimator:\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, batch_size=4, num_epochs=1000)\n",
    "eval_input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000)\n",
    "    \n",
    "# Update the model (estimator) with the training data:\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Evaluate the model:\n",
    "train_loss = estimator.evaluate(input_fn=input_fn)\n",
    "eval_loss = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"Train loss: %r\" % train_loss)\n",
    "print(\"Eval loss: %r\" % eval_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
